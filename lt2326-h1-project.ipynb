{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook contains the code for training and evaluating a Sequence to Sequence (seq2seq) Encoder - Decoder model for semantic role labeling (SRL), as project for the course LT2326, autumn 2021. Data preparation is defined and handled elsewhere; see `data_builder.ipynb`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On torchtext module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seemed to be no installation of `torchtext`, so I ran:\n",
    "\n",
    "```pip install torchtext==0.10.0```\n",
    "\n",
    "which shold be compatible with `torch` version 1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, time, operator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import torch.nn.functional as F\n",
    "#from torchtext.data import Field, BucketIterator, Iterator, TabularDataset\n",
    "from torchtext.legacy.data import Field, BucketIterator, Iterator, TabularDataset # Needed for running this on my laptop\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define where to get and store data and which device to use. For test pipline with less data during development set `mini_training`to `True`; when using complete dataset, set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "my_data_directory = \"../data/\" # MLTGPU\n",
    "\n",
    "my_models_directory = \"../models/\" #MLTGPU\n",
    "\n",
    "mini_testing = False\n",
    "my_train_file = \"mini_train.csv\" if mini_testing == True else \"train.csv\"\n",
    "my_test_file  = \"mini_test.csv\" if mini_testing == True else \"test.csv\"\n",
    "\n",
    "dir_for_evaluations = \"../evals/\" #MLTGPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(directory  = my_data_directory,\n",
    "               train_file = my_train_file,\n",
    "               test_file  = my_test_file,\n",
    "               batch      = batch_size):\n",
    "    \n",
    "    whitespacer = lambda x: x.split(\" \")\n",
    "    num_whitespacer = lambda x: [int(e) for e in x.split(\" \")]\n",
    "    \n",
    "    SENTENCE = Field(tokenize = whitespacer, \n",
    "                     lower = True,\n",
    "                     batch_first = True, \n",
    "                     init_token = \"<sos>\", \n",
    "                     eos_token = \"<eos>\")\n",
    "    \n",
    "    PREDICATE = Field(tokenize = num_whitespacer, # Here might be some problems ...\n",
    "                      batch_first = True, \n",
    "                      pad_token = 0,\n",
    "                      use_vocab = False,\n",
    "                      init_token = 0, \n",
    "                      eos_token = 0) \n",
    "    \n",
    "    SRLABEL = Field(batch_first = True, \n",
    "                    init_token = \"<sos>\", \n",
    "                    eos_token = \"<eos>\")\n",
    "    \n",
    "    my_fields = [(\"sentence\", SENTENCE),\n",
    "                 (\"predicate\", PREDICATE),\n",
    "                 (\"srlabel\", SRLABEL)]\n",
    "    \n",
    "    train, test = TabularDataset.splits(path   = directory,\n",
    "                                        train  = train_file,\n",
    "                                        test   = test_file,\n",
    "                                        format = 'csv',\n",
    "                                        fields = my_fields,\n",
    "                                        csv_reader_params = {'delimiter':'\\t',\n",
    "                                                             'quotechar':'Â¤'}) # Seems not to be in data\n",
    "    SENTENCE.build_vocab(train)\n",
    "    SRLABEL.build_vocab(train)  \n",
    "\n",
    "    train_iter, test_iter = BucketIterator.splits((train, test),\n",
    "                                                  batch_size        = batch,\n",
    "                                                  sort_within_batch = True,\n",
    "                                                  sort_key          = lambda x: len(x.sentence),\n",
    "                                                  shuffle           = True,\n",
    "                                                  device            = device)\n",
    "\n",
    "    return train_iter, test_iter, SENTENCE.vocab, SRLABEL.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, vocab, labels = dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: 0\n",
      "<sos> recommended . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 1\n",
      "<sos> roll over . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 9\n",
      "<sos> switch teams . <eos>\n",
      "tensor([[0, 0, 0, 1, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 24\n",
      "<sos> ready to drink ? <eos>\n",
      "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:1')\n",
      "ERROR: 27\n",
      "<sos> easy to use . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 35\n",
      "<sos> journey time approx . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 36\n",
      "<sos> list of forms affected <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 54\n",
      "<sos> ( to appear ) . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0]], device='cuda:1')\n",
      "ERROR: 60\n",
      "<sos> what a carve up ! <eos>\n",
      "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 91\n",
      "<sos> i am lost for words . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 105\n",
      "<sos> there <unk> . ' chap ! <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0]], device='cuda:1')\n",
      "ERROR: 124\n",
      "<sos> aluminium handle with water channel . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 163\n",
      "<sos> highly commended : wymondham & attleborough . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 181\n",
      "<sos> result : stomach far from happy . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 219\n",
      "<sos> featured venue the spitz gallery - element 3 <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 283\n",
      "<sos> revised and updated for 2000 - 2001 . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:1')\n",
      "ERROR: 405\n",
      "<sos> tel : 01452 <unk> to make an appointment . <eos>\n",
      "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]], device='cuda:1')\n",
      "ERROR: 449\n",
      "<sos> tom cat and the wideawake mice 21 . ? <eos>\n",
      "tensor([[0, 0, 1, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 450\n",
      "<sos> can even that minority really make proper choices ? <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 618\n",
      "<sos> keep not doing so for time or tiredness purposes . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 634\n",
      "<sos> london : <unk> ( expected publication date september 2006 ) <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], device='cuda:1')\n",
      "ERROR: 669\n",
      "<sos> adoption and fostering 1997 ; 21 : 36 - 40 . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:1')\n",
      "ERROR: 673\n",
      "<sos> adoption and fostering 1999 ; 23 : 40 - 48 . <eos>\n",
      "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 733\n",
      "<sos> commitment to individuals ' long - term learning and development . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:1')\n",
      "ERROR: 754\n",
      "<sos> take the m25 to junction 9 , exit for <unk> . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 916\n",
      "<sos> at roundabout where a25 crosses the a24 take the a24 ( i.e. <eos>\n",
      "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 1053\n",
      "<sos> 0 points section 4 . audio quality , 40 points essential . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]], device='cuda:1')\n",
      "ERROR: 1152\n",
      "<sos> highly commended : link - line tm , west shropshire tn . <eos>\n",
      "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 1163\n",
      "<sos> until this summer , that was being done on manpower planning spreadsheets . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 1259\n",
      "<sos> barrett , the <unk> \" was \" well known in chichester \" . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 1391\n",
      "<sos> paris is linked to the high speed rail network ( <unk> ) . <eos>\n",
      "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]], device='cuda:1')\n",
      "ERROR: 1399\n",
      "<sos> cotis audio category : joint winners : chichester area & norfolk tns . <eos>\n",
      "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 1585\n",
      "<sos> high quality printable puzzles in eps / pdf format , ready to print . <eos>\n",
      "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 1852\n",
      "<sos> lionel trilling , ' the ninth as literature ' , encounter 3 , no . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 1972\n",
      "<sos> phone : 0845 345 <unk> ( 9 am to 5 pm monday to friday . <eos>\n",
      "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 2431\n",
      "<sos> ( 1.1 mb ) turbo <unk> the charge - <unk> fiat coupe 20 v turbo . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 2478\n",
      "<sos> travellers ' tales ( working title ) , and autumn leaves ( working title ) . <eos>\n",
      "tensor([[0, 0, 1, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 2493\n",
      "<sos> the salzburg lakes a 7 night walking holiday around austria 's lake district level 1 . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 2757\n",
      "<sos> ( 18 ) <unk> . <unk> , ' the gospel according to matthew ' , <unk> . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0]], device='cuda:1')\n",
      "ERROR: 2977\n",
      "<sos> publication <unk> animal choices isbn 0 906562 236 ( university of leeds , september 1996 ) . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:1')\n",
      "ERROR: 3204\n",
      "<sos> ways of making such as pinching , slab - building , <unk> , slip casting and throwing . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:1')\n",
      "ERROR: 3760\n",
      "<sos> chairman , burn gliding club , selby entry made : <unk> thu sep 9 2004 name : <unk> . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 3852\n",
      "<sos> highly commended : chichester area , kenilworth , north norfolk , stowmarket & district , southampton talking echo . <eos>\n",
      "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 4403\n",
      "<sos> mather m , humphrey j , <unk> j . the statutory medical and health needs of looked after children . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:1')\n",
      "ERROR: 4807\n",
      "<sos> opening times mondays only ( except bank holidays ) 11 am - 3 pm or by prior arrangements for groups . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 4833\n",
      "<sos> <unk> an <unk> <unk> <unk> sie <unk> , <unk> die <unk> , die gekoppelte hypothek <unk> , <unk> <unk> <unk> . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 5083\n",
      "<sos> updated jul 12 , 2006 pitti bimbo spring summer 07 pitti bimbo snap report : timberland / marithe & <unk> girbaud . <eos>\n",
      "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]], device='cuda:1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: 6783\n",
      "<sos> introduction note : * copyright 1993 association for computing machinery , inc . this electronic reprint made available by the author as a courtesy . <eos>\n",
      "tensor([[0, 0, 0, 1, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 6882\n",
      "<sos> opening hours : from 30 th june to 29 th august , every sunday and bank holiday monday from 2.00 pm to 5.00 pm . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:1')\n",
      "ERROR: 7669\n",
      "<sos> tel ( freephone ) : 0808 <unk> 4000 ( 9 am to 9 pm monday to friday and 9.30 am to 1 pm saturday ) . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:1')\n",
      "ERROR: 8969\n",
      "<sos> ( northumberland railway walks society ) left : ham green viaduct , north of <unk> , on the former gwr branch line from plymouth to tavistock and <unk> . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 9238\n",
      "<sos> by fransoir ( <unk> a.cache.pol.co.uk - <unk> ) on sunday , june 03 , 2001 - 09 : 54 pm : edit our <unk> a <unk> bloke colbar ! <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 9816\n",
      "<sos> in this medium , texts can be linked to notes , to variants , to other texts , even to graphics or sound or movies , or to itself . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 9998\n",
      "<sos> candidate ref : sci <unk> required salary : $ 35 k + title : regional sales manager description : three years sales experience in the liquid handling consumables market . <eos>\n",
      "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:1')\n",
      "ERROR: 10164\n",
      "<sos> 27 c 60 / 32 , fine roll 17 henry iii ( 28 october 1232 - 27 october 1233 ) , membrane 6 . 140 for ranulf and william brito . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0]], device='cuda:1')\n",
      "ERROR: 11809\n",
      "<sos> resources database the role of research publication date : 28 sep 2001 resource type : article download publication : <unk> ( adobe acrobat ) resource description : professionals make more informed professional judgments . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 12249\n",
      "<sos> in a sixth place , devizes , the acquisition of southern 's free title would give westminster press 100 per cent of the market for weekly newspapers , both paid - for and free . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:1')\n",
      "ERROR: 12538\n",
      "<sos> phone : 0870 770 <unk> ( 11 am to 4 pm monday to friday ) web : <unk> e - parents the national family and parenting institute 's information and advice website for parents . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], device='cuda:1')\n",
      "ERROR: 12944\n",
      "<sos> journal of epidemiology and community health 2002 ; 56 : <unk> omission of active commuting to school and the prevalence of children 's health - related physical activity levels : the russian <unk> monitoring study . <eos>\n",
      "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 13040\n",
      "<sos> phone : 08457 47 47 47 ( 8 am to 6 pm monday to friday ) textphone : 0845 606 1600 web : www.dti.gov.uk / <unk> national minimum wage for information on the national minimum wage . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 14436\n",
      "<sos> sudoku puzzles - sudoku collection - free printable and online sudoku puzzles free printable sudoku puzzles with various levels of difficulty , plus big sudoku , giant sudoku , daily printable sudoku , online sudoku and kids sudoku puzzles . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 16377\n",
      "<sos> 3 . quoted in ' hubert de burgh ' , 47 ; <unk> of dunstable , from , hr <unk> ed . , <unk> <unk> , 4 vols . , rolls ser . , ( hmso , 1864 - 1869 ) , iii , 84 . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:1')\n",
      "ERROR: 16695\n",
      "<sos> other small business grant | home daycare small business grant | small business grant | small business <unk> grant | small business winning grant proposals | <unk> small business grant | grant for small business for <unk> | small business grant michigan | small business grant <unk> <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 16799\n",
      "<sos> ; murray 's life <unk> rutherford . ] 1639 william <unk> , born 1599 , son of james d . , grandson of robert d . of that <unk> ; m.a . ( st andrews <unk> ) ; ord . to <unk> <unk> ; <unk> . by <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 19230\n",
      "<sos> phone : 08457 133 133 ( 8 am to 8 pm monday to friday and 9 am to 5 pm saturday ) minicom : 08457 138 <unk> welsh language : 08457 138 <unk> ( 8 am to 8 pm monday to friday ) web : <unk> disability and carers service a part of the department for work and pensions . <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 19813\n",
      "<sos> opening times : castle open easter ( 21 - 24 apr ) , 29 apr - 3 may , daily , 1300 - 1700 ; 6 - 31 may , 2 - 27 sep , wed , sun , 1300 - 1700 ; 1 jun - 31 aug , daily , except sat , 1300 - 1700 ; park and gardens open 1100 - <unk> . <eos>\n",
      "tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 20256\n",
      "<sos> <unk> & wildlife ( 12 days ) <unk> <unk> ( 20 days ) <unk> mountain trek ( 14 days ) southern yunnan adventure ( 10 days ) <unk> explorer ( 10 nights ) the <unk> track ( 15 days ) the middle kingdom ( 15 days ) <unk> np roof of the world ( 13 days ) western desert expedition ( 16 days ) yunnan mountain trek ( 14 days ) <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 21799\n",
      "<sos> like home - rolling <unk> no place that far - <unk> evans no place that far - <unk> evans no place to hide - <unk> no plan b - 4 th avenue jones ' no <unk> for <unk> - <unk> no <unk> ser <unk> - <unk> no power on earth - george <unk> no prayer for the dying [ <unk> ] [ remastered ] - iron maiden no presents for me - <unk> no pressure [ pa ] - <unk> <unk> no <unk> donna ( a tribute to van morrison ) - various artists no problem - <unk> <unk> no problem - <unk> baker quartet no problem - igm & edwin yearwood <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 22871\n",
      "<sos> own , south africa free night combination | save $ 147 pp lion sands private game reserve , ivory lodge , sabi sands game reserve free night | save up to $ 415 pp leopard hills private game reserve , sabi sand , south africa free night | save up to $ 125 pp the mount nelson , cape town , south africa free night | save $ 120 pp the table bay , cape town , south africa value - added offer <unk> <unk> , kruger national park , south africa family offer - children stay free cape grace , cape town , south africa family offer - child stays free the mount nelson , cape town , south africa <unk> nights the marine , hermanus , south africa honeymoon offer the table bay , cape town , south africa <unk> helicopter flight leopard hills private game reserve , sabi sand , south africa <unk> nights cape grace , cape town , south africa <unk> nights the cellars - <unk> , cape town , south africa <unk> nights the plettenberg , plettenberg bay , south africa ideal for city breaks desert a <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: 22955\n",
      "<sos> <unk> , 2000 ) jackson , russell ( ed ) , the cambridge companion to shakespeare on film ( cup , 2000 ) johnson , david , shakespeare and south africa ( oxford university press , 1996 ) <unk> , jack , shakespeare on film ( up of america , 1991 ) <unk> , john ( ed ) , shakespeare and national culture ( manchester university press , 1997 ) <unk> , john ( ed ) , philosophical <unk> ( routledge , 2000 ) <unk> , david , shakespeare after theory ( routledge , 1999 ) <unk> , jan , shakespeare our contemporary ( routledge , 1981 ) <unk> , <unk> , post - colonial <unk> ( routledge , 1998 ) <unk> , gordon , renaissance configurations ( palgrave , 1998 ) <unk> , martin , ' the shakespeare connection ' in <unk> , drama and the south african state ( manchester university press , 1991 ) [ offprints ] <unk> , linda , shakespeare and the politics of culture in late victorian england ( <unk> hopkins up , 1998 ) <unk> , kenneth , a history of shakespeare on screen ( cup , 1999 ) shaughnessy , <unk> <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:1')\n",
      "ERROR: 23044\n",
      "<sos> end of year - teacher assessments in english , maths and science attainment targets ( w , 1 c , 1 b , 1 a , 2 c 2 b , 2 a , 3 c , 3 b , 3 a ) year three may - optional sats ( reading , writing , spelling , maths ) sept , jan , jun - salford sentence reading test , spar spelling test april - nfer reading , maths , non - verbal tests end of year - teacher assessments in english , maths and science attainment targets ( w,1,2 a,2 b,2 c,3 a,3 b,3 c,4 a,4 b,4 c ) year four may - optional sats ( reading , writing , spelling , maths ) sept , jan , jun - salford sentence reading test , spar spelling test april - nfer reading , maths , nonverbal tests end of year - teacher assessments in english , maths and science attainment targets ( w,1,2 a,2 b,2 c,3 a,3 b,3 c,4 a,4 b,4 c ) year five may - optional sats ( reading , writing , spelling , maths ) sept , jan , jun - salford sentence reading test , spar spelling test april - nfer reading , maths , nonverbal tests end of year - teacher assessments in english , maths and science attainment targets ( w,1,2 a,2 b,2 <eos>\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:1')\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "e=0\n",
    "for i, x in enumerate(test):\n",
    "    if x.sentence.shape != x.predicate.shape:\n",
    "        e += 1\n",
    "        print(\"ERROR:\", i)\n",
    "\n",
    "        print(\" \".join([vocab.itos[x] for x in x.sentence[0]]))\n",
    "        print(x.predicate)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder encodes sentence-predicate pairs through LSTMs. In forward pass, it returns *the final cell state* and *the final hidden state* (somtimes referred to as the *context vector*).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRL_Encoder(nn.Module):\n",
    "    def __init__(self, voc_size, embedding_size, hidden_size, n_layers, p_dropout):  \n",
    "        super(SRL_Encoder, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(voc_size, embedding_size)\n",
    "        self.sp_pair = embedding_size + 1 # emedded sentence + predicate vector\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.rnn = nn.LSTM(self.sp_pair, \n",
    "                           self.hidden_size, \n",
    "                           num_layers = self.n_layers,\n",
    "                           dropout = p_dropout,\n",
    "                           #bidirectional=True, # !\n",
    "                           batch_first=True) # !\n",
    "        self.dropout = nn.Dropout(p_dropout)\n",
    "        \n",
    "    def forward(self, sentences, pred_vec):\n",
    "        \n",
    "        embeddings = self.embeddings(sentences)\n",
    "        pred_vec = pred_vec.unsqueeze(2)        \n",
    "        sentence_pred_pair = torch.cat((embeddings, pred_vec), dim=2)\n",
    "        contextualized_embedding, (hidden_final, cell_final) = self.rnn(sentence_pred_pair)\n",
    "        \n",
    "        #print(\"ENC, hidden:\", hidden_final.shape)\n",
    "        #print(\"ENC, cell:\", cell_final.shape)\n",
    "        \n",
    "        return hidden_final, cell_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder predicts the next element of a sequence based on the previous sequence and the final cell state and the final hidden state of that sequence through an LSTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRL_Decoder(nn.Module):\n",
    "    def __init__(self, n_labels, embedding_size, hidden_size, n_layers, p_dropout):  \n",
    "        super(SRL_Decoder, self).__init__()\n",
    " \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "        self.embeddings = nn.Embedding(n_labels, embedding_size) # ?\n",
    "        self.rnn = nn.LSTM(embedding_size, \n",
    "                           self.hidden_size, \n",
    "                           num_layers = self.n_layers, \n",
    "                           batch_first=True,\n",
    "                           #bidirectional=True,\n",
    "                           dropout = p_dropout)\n",
    "        self.classifier = nn.Linear(hidden_size, self.n_labels)\n",
    "        \n",
    "    def forward(self, previous, hidden, cell):\n",
    "        \n",
    "        #previous = previous.unsqueeze(1)\n",
    "        \n",
    "        embedded = self.embeddings(previous)\n",
    "        #print(\"DEC, emb_previous:\", embedded.shape)\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.classifier(output)\n",
    "        \n",
    "        return prediction, hidden, cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder - Decoder Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `SRL_Seq2SeqLabeler`, the context vector (i.e. final cell and hidden states) of the `Encoder` together with the start token `<sos>` serves as inputs to predict a sequence of semantic role labels. After the first prediction, the decoder uses its own predictions as the input sequence to predict the next token. This model uses teacher forcing, meaning that, at some proportion of the time, as defined by a teacher force ratio (TFR), the true label of the sequence is put into the sequence, instead of the prediction by the encoder. \n",
    "\n",
    "Minor note: the classification problem engaged with here is a one-to-one mapping. Translation problems more generally might involve mappings of sequences of different lengths. To handle mappings of different lengths properly would require further work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRL_Seq2SeqLabeler(nn.Module):\n",
    "    def __init__(self, encoder, decoder):  \n",
    "        super(SRL_Seq2SeqLabeler, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        assert encoder.hidden_size == decoder.hidden_size, \"hidden dimension of encoder must be equal to that of decoder\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \"n_layers of encoder must be equal to that of decoder\"\n",
    "        \n",
    "    def forward(self, sentence, predicate, srl_labels, tfr = None): # tfr = teacher forcing ratio\n",
    "\n",
    "        batch_size = sentence.shape[0]\n",
    "        seq_len = sentence.shape[1]\n",
    "        n_labels = self.decoder.n_labels\n",
    "\n",
    "        outputs = torch.zeros(batch_size, seq_len, n_labels).to(device) # for storage\n",
    "\n",
    "        hidden, cell = self.encoder(sentence, predicate)\n",
    "\n",
    "        seq_element = srl_labels[:, 0].unsqueeze(1) # start of sentence token; index of <sos>\n",
    "        #print(\"S2S, Seq_elem, prior:\", seq_element)\n",
    "\n",
    "        for l in range(1, seq_len): # Note: starts from 1; first column of outputs will \"remain\" 0\n",
    "            \n",
    "            #print(\"S2S, Seq_elem:\", seq_element.shape)\n",
    "\n",
    "            output, hidden, cell = self.decoder(seq_element, hidden, cell)\n",
    "            #print(\"S2S, Outputs:\", outputs.shape)\n",
    "            #print(\"S2S, Output:\", output.shape)\n",
    "            outputs[:, l, :] = output.squeeze()\n",
    "            best_guess = output.argmax(2)\n",
    "            #print(\"S2S, Best guess:\", best_guess)\n",
    "\n",
    "            if tfr != None:\n",
    "                teacher_force = random.random() < tfr\n",
    "#                 if teacher_force:\n",
    "#                     print(\"TF\")\n",
    "#                 else:\n",
    "#                     print(\"No TF\")\n",
    "                seq_element = srl_labels[:, l].unsqueeze(1) if teacher_force else best_guess\n",
    "            else:\n",
    "                seq_element = best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, # Must be an instance of a model!\n",
    "            name_of_model,\n",
    "            learning_rate,\n",
    "            epochs,\n",
    "            data,\n",
    "            my_tfr = 0.5,\n",
    "            val_data = None,\n",
    "            save_model = False,\n",
    "            directory = my_models_directory,\n",
    "            my_loss_function = nn.CrossEntropyLoss,\n",
    "            my_optimizer = optim.Adam\n",
    "           ):\n",
    "    \"\"\" Specifices a general training procedure for a model. \n",
    "        Note: trainer() requires an instantiated model as model argument. \n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer = my_optimizer(model.parameters(), lr=learning_rate)    \n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    pad_idx = labels.stoi[\"<pad>\"]\n",
    "    \n",
    "    loss_function = my_loss_function(ignore_index=pad_idx) # We ignorew pad token in loss calculation\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for i, batch in enumerate(data):\n",
    "            optimizer.zero_grad # reset gradients\n",
    "            \n",
    "            sentence = batch.sentence\n",
    "            predicate = batch.predicate\n",
    "            targets = batch.srlabel\n",
    "            #print(\"TRAIN, Targets:\", targets.shape)\n",
    "            \n",
    "            output = model(sentence, predicate, targets, tfr = my_tfr)\n",
    "            #print(\"TRAIN, Output:\", output.shape)\n",
    "            \n",
    "            # Before calculation of loss outputs and targets needs to be \"aligned\", so to speak.\n",
    "            # Outputs are of shape [batch, seq_len, dimension]. Targets of shape [batch, seq_len]\n",
    "            # The representation of the first element of the output sequence will be 0s (see \n",
    "            # above). The first element of the targets will be <sos>. We ignore these first elements\n",
    "            # in calculating the loss. \n",
    "            \n",
    "            # Moreover, our loss function (CrossEntropyLoss) expects predicitons as [n_predictions, \n",
    "            # n_classes] and targets as [n_predictions]. Here, n_predictions = batch_size * sequence_\n",
    "            # length. \n",
    "            \n",
    "            bsz = output.shape[0]\n",
    "            length = output.shape[1]\n",
    "            output_dim = output.shape[2]\n",
    "        \n",
    "            output = output[:, 1:, :].reshape(bsz*(length - 1), output_dim) # first token (\"column\") being zeroes\n",
    "            targets = targets[:, 1:].flatten() # first token being <sos>\n",
    "            \n",
    "            # Now, calculate the loss\n",
    "            loss = loss_function(output, targets)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward() # compute gradients\n",
    "            optimizer.step() # update parameters\n",
    "            #break\n",
    "            \n",
    "        print(f\"Epoch: {epoch+1} (out of {epochs}); total loss: {epoch_loss}.\")\n",
    "            \n",
    "        if val_data != None:\n",
    "            model.eval()\n",
    "            # Here we could do some evaluation of model progress, but I have ignored this for now. \n",
    "            model.train()\n",
    "            \n",
    "    if save_model == True:\n",
    "        torch.save(model, directory+name_of_model+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples from the web:\n",
    "\n",
    "|Author            |No. of layers|Batch Size|Embeddingsdim.|Hidden Dim.|Dropout|WWW             |\n",
    "|------------------|-------------|----------|--------------|-----------|-------|---------|\n",
    "|Ziqi Yuan         |            2|       128|           256|        512|    0.5|https://www.kaggle.com/columbine/seq2seq-pytorch|\n",
    "|Balakrishnakumar V|            2|        32|           300|       1024|    0.5|https://towardsdatascience.com/a-comprehensive-guide-to-neural-machine-translation-using-seq2sequence-modelling-using-pytorch-41c9b84ba350|\n",
    "|Matthew Inkawhich |            2|        64|           ?  |        500|    0.1|https://pytorch.org/tutorials/beginner/deploy_seq2seq_hybrid_frontend_tutorial.html|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_epochs = 10\n",
    "learning_rate = 0.001\n",
    "# batch size defined before calling dataloader\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "num_labels = len(labels)\n",
    "emb_sizeE = 256\n",
    "emb_sizeD = num_labels\n",
    "#emb_sizeD = int(num_labels/2) # embeddings for labels\n",
    "hid_size_encoder = 512\n",
    "hid_size_decoder = hid_size_encoder # ?\n",
    "\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_encoder = SRL_Encoder(vocab_size, emb_sizeE, hid_size_encoder, num_layers, p_dropout=0.2)\n",
    "my_decoder = SRL_Decoder(num_labels, emb_sizeD, hid_size_decoder, num_layers, p_dropout=0.2)\n",
    "my_SRLLabeler = SRL_Seq2SeqLabeler(my_encoder, my_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Know your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_encoder.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_decoder.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_name = f\"srl_b{batch_size}_e{my_epochs}_minisample\" if mini_testing else f\"srl_b{batch_size}_e{my_epochs}_csample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer(model = my_SRLLabeler, \n",
    "        name_of_model = model_name, \n",
    "        learning_rate = learning_rate, \n",
    "        epochs = my_epochs, \n",
    "        data = train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation, several functions are defined. Also, a class for managing information from evalution is defined. Overall, the model is evaluated by\n",
    "*    its accuracy (number of correct predictions / total)\n",
    "*    F1 averaged globally\n",
    "*    F1 averaged by mean\n",
    "*    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of labels\n",
    "lst_labels = [labels.itos[x] for x in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_labels #remove stuff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and a class for handling information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCES:\n",
    "# https://www.baeldung.com/cs/multi-class-f1-score\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "\n",
    "def metrics(prediction, \n",
    "            truth \n",
    "            #labels = lst_labels\n",
    "           ):\n",
    "    \"\"\" Calculates accuracy and F1, given two sequences (lists, arrays) of labels. Since, \n",
    "        these metrices here are calculated for multi-label classification, two versions \n",
    "        of F1 are calculated: \"macro\" and \"micro\", where the former is the mean of F1 for\n",
    "        each label, and the latter is calculated globally by counting the total true \n",
    "        positives, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(prediction, len(prediction))\n",
    "    print(truth, len(truth))\n",
    "    \n",
    "    \n",
    "    #f1_dict = {}\n",
    "    \n",
    "    accuracy = accuracy_score(truth, prediction)\n",
    "    #f1_lsted = f1_score(truth, prediction, labels = labels, average = None, zero_division = 0)\n",
    "    f1_macro = f1_score(truth, prediction, average = \"macro\") # Calculate metrics for each label, and find their unweighted mean. Does not take label imbalance into account.\n",
    "    f1_micro = f1_score(truth, prediction, average = \"micro\") # Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "    \n",
    "#    for label in labels:\n",
    "#        f1_dict[label] = f1_lsted[labels.index(label)] # overkill?\n",
    "\n",
    "    return accuracy, f1_macro, f1_micro\n",
    "#    return accuracy, f1_macro, f1_micro, f1_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(array):\n",
    "    \"\"\" Calculates the mean and standard deviation of an aray of numbers.\n",
    "    \"\"\"\n",
    "    mean = np.mean(array)\n",
    "    std  = np.std(array)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    \"\"\" For storing and handling information from the evaluation of model(s).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "        self.pooled_acc      = \"Not yet defined\"\n",
    "        self.pooled_f1_macro = \"Not yet defined\"\n",
    "        self.pooled_f1_micro = \"Not yet defined\" \n",
    "        \n",
    "        self.mean_acc        = (\"Not yet defined\", \"Not yet defined\")\n",
    "        self.mean_f1_macro   = (\"Not yet defined\", \"Not yet defined\")\n",
    "        self.mean_f1_micro   = (\"Not yet defined\", \"Not yet defined\")\n",
    "        \n",
    "        self.corr_l_acc      = \"Not yet defined\"\n",
    "        self.corr_l_f1_macro = \"Not yet defined\"\n",
    "        self.corr_l_f1_micro = \"Not yet defined\"\n",
    "        \n",
    "        self.confusion = {\"Not yet defined\": {\"Not yet defined\": \"Not yet defined\"}}\n",
    "        self.metrics_dict = {\"accuracy\": [\"Not yet defined\", \"Not yet defined\"], \n",
    "                             \"f1_macro\": [\"Not yet defined\", \"Not yet defined\"], \n",
    "                             \"f1_micro\": [\"Not yet defined\", \"Not yet defined\"]}\n",
    "\n",
    "    def best_case(self, metric):\n",
    "        \"\"\" Returns the file which has the best performance score with respect \n",
    "            to a metric.\n",
    "        \"\"\"\n",
    "        m_list = self.metrics_dict[metric]\n",
    "        zic_zac = False if metric == \"mse\" else True\n",
    "        m_list.sort(key=operator.itemgetter(1), reverse=zic_zac)\n",
    "        return m_list[0][0]\n",
    "    \n",
    "    def best_cases(self, metric, n):\n",
    "        \"\"\" Returns a list of the N files which has the best performance score \n",
    "            with respect to a metric.\n",
    "        \"\"\"\n",
    "        m_list = self.metrics_dict[metric]\n",
    "        zic_zac = False if metric == \"mse\" else True\n",
    "        m_list.sort(key=operator.itemgetter(1), reverse=zic_zac)\n",
    "        files, values = zip(*m_list)\n",
    "        return list(files[:n])\n",
    "    \n",
    "    def worst_case(self, metric):\n",
    "        \"\"\" Returns the file which has the best performance score with respect \n",
    "            to a metric.\n",
    "        \"\"\"\n",
    "        m_list = self.metrics_dict[metric]\n",
    "        zic_zac = True if metric == \"mse\" else False\n",
    "        m_list.sort(key=operator.itemgetter(1), reverse=zic_zac)\n",
    "        return m_list[0][0]\n",
    "\n",
    "    def worst_cases(self, metric, n):\n",
    "        \"\"\" Returns a list of the N files which has the best performance score \n",
    "            with respect to a metric.\n",
    "        \"\"\"\n",
    "        m_list = self.metrics_dict[metric]\n",
    "        zic_zac = True if metric == \"mse\" else False\n",
    "        m_list.sort(key=operator.itemgetter(1), reverse=zic_zac)\n",
    "        files, values = zip(*m_list)\n",
    "        return list(files[:n])\n",
    " \n",
    "    def summary(self):\n",
    "        \"\"\" Summarises an evaluation. Returns string.\"\"\"\n",
    "        summary  = \"\\n\".join([f\"Model {self.name} performs as follows:\", \n",
    "                      f\"Pooled Accuracy: {self.pooled_acc}\",\n",
    "                      f\"Pooled F1_macro: {self.pooled_f1_macro}\",\n",
    "                      f\"Pooled F1_micro: {self.pooled_f1_micro}\",\n",
    "                              \n",
    "                      f\"Mean Accuracy: {self.mean_acc[0]} (std = {self.mean_acc[1]})\",\n",
    "                      f\"Mean F1_macro: {self.mean_f1_macro[0]} (std = {self.mean_f1_macro[1]})\",\n",
    "                      f\"Mean F1_micro: {self.mean_f1_micro[0]} (std = {self.mean_f1_micro[1]})\",\n",
    "                      \n",
    "                      f\"Correlation sentence length and accuracy: {self.corr_l_acc}\",\n",
    "                      f\"Correlation sentence length and F1_macro: {self.corr_l_f1_macro}\",\n",
    "                      f\"Correlation sentence length and F1_micro: {self.corr_l_f1_micro}\"]) \n",
    "        return summary\n",
    "    \n",
    "    def confusion_matrix(self):\n",
    "        \"\"\" Returns and prints a confusion matrix. \n",
    "        \"\"\"\n",
    "        \n",
    "        srl_labels = list(self.confusion.keys())\n",
    "        \n",
    "        matrix = [[\"\"] + srl_labels] # headings\n",
    "        for l in srl_labels:\n",
    "            row = [l]\n",
    "            for k in srl_labels:\n",
    "                row.append(str(self.confusion[l][k]))\n",
    "            matrix.append(row)\n",
    "            \n",
    "        #matrix_txt = [[str(cell) for cell in row] for row in matrix]\n",
    "        \n",
    "        txt = \"\\n\".join([\"\\t\".join(row) for row in matrix])\n",
    "        \n",
    "        #print(txt)\n",
    "        return txt\n",
    "    \n",
    "    def save(self, metric, directory=dir_for_evaluations):\n",
    "        \"\"\" Writes the summary of an evaluation to a text file (at some diectory).\"\"\"\n",
    "        \n",
    "        summary = self.summary()\n",
    "        confusion_matrix = self.confusion_matrix()\n",
    "        best_sentences = \"\\n\".join([f\"Best sentences ({metric}):\"] + self.best_cases(metric, 5))\n",
    "        worst_sentences = \"\\n\".join([f\"Worst sentences ({metric}):\"] + self.worst_cases(metric, 5))\n",
    "        \n",
    "        output_to_save = summary + \"\\n\" + confusion_matrix + \"\\n\" + best_sentences + \"\\n\" + worst_sentences\n",
    "        \n",
    "        with open(f\"{directory}{self.name}_{metric}.txt\", \"w\") as e:\n",
    "            e.write(output_to_save)\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\" Prints out the summary of an evaluation.\n",
    "        \"\"\"\n",
    "        summary = self.summary()\n",
    "        print(summary)\n",
    "        \n",
    "    def print_confusion_matrix(self):\n",
    "        \"\"\" Prints out the confusion matrix.\n",
    "        \"\"\"\n",
    "        c_matrix = self.confusion_matrix()\n",
    "        print(c_matrix)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(model, name, test_data = test, srl_labels = lst_labels, detach_me=False):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    t1 = time.perf_counter()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    evaluation = Evaluation(name)\n",
    "    \n",
    "    prediction_pooled = [] # to collect all predictions\n",
    "    truth_pooled = []      # to collect all true labels\n",
    "    seq_lengths = []       # to collect the length of sentences\n",
    "    confusion = {label: {label: 0 for label in srl_labels} for label in srl_labels} # for confusion matrix\n",
    "    metrics_calc = {\"accuracy\": [], \"f1_macro\": [], \"f1_micro\": []} # to collect accuracy and f1 for every sentence\n",
    "    \n",
    "    #i=1 # in order to print out progress\n",
    "    for batch in test_data:\n",
    "        sentence = batch.sentence\n",
    "        predicate = batch.predicate\n",
    "        truth = batch.srlabel\n",
    "        \n",
    "        \n",
    "            \n",
    "        if detach_me == True: # to avoid some CUDA memory shortage issues\n",
    "            prediction = model(sentence, predicate, truth).detach().to(\"cpu\")\n",
    "            truth = batch.srlabel.detach().to(\"cpu\")\n",
    "        \n",
    "        else:\n",
    "            prediction = model(sentence, predicate, truth) \n",
    "        \n",
    "        batched_pred_labels = prediction[:, 1:, :].argmax(2) # ... should not be batch-wise, but sentence-wise\n",
    "        batched_true_labels = truth[:, 1:]\n",
    "        \n",
    "        bsz = batched_pred_labels.shape[0]\n",
    "        \n",
    "        for b in range(bsz):\n",
    "            str_sent    = \" \".join([vocab.itos[token] for token in sentence[b]]) # to list?\n",
    "            seq_len     = len([x for x in sentence[b] if vocab.itos[x] not in [\"<pad>\", \"<sos>\", \"<eos>\"]])\n",
    "            pred_labels = batched_pred_labels[b].tolist()\n",
    "            true_labels = batched_true_labels[b].tolist()\n",
    "            \n",
    "            #accuracy, f1_macro, f1_micro, X = metrics(true_labels, pred_labels)\n",
    "            accuracy, f1_macro, f1_micro = metrics(true_labels, pred_labels)\n",
    "            \n",
    "            prediction_pooled.extend(pred_labels)\n",
    "            truth_pooled.extend(true_labels)\n",
    "            seq_lengths.append(seq_len)\n",
    "            \n",
    "            for p, t in zip(pred_labels, true_labels):\n",
    "                confusion[srl_labels[p]][srl_labels[t]] += 1\n",
    "                \n",
    "            for m, v in zip([\"accuracy\", \"f1_macro\", \"f1_micro\"], [accuracy, f1_macro, f1_micro]):\n",
    "                metrics_calc[m].append( (str_sent, v) )\n",
    "    \n",
    "    #print(prediction_pooled)\n",
    "    \n",
    "    #pooled_accuracy, pooled_f1_macro, pooled_f1_micro, X = metrics(truth_pooled, prediction_pooled)\n",
    "    pooled_accuracy, pooled_f1_macro, pooled_f1_micro = metrics(truth_pooled, prediction_pooled)\n",
    "\n",
    "    lst_accuracy = list(zip(*metrics_calc[\"accuracy\"]))[1]\n",
    "    lst_f1_macro = list(zip(*metrics_calc[\"f1_macro\"]))[1]\n",
    "    lst_f1_micro = list(zip(*metrics_calc[\"f1_micro\"]))[1]\n",
    "\n",
    "    evaluation.pooled_acc      = pooled_accuracy\n",
    "    evaluation.pooled_f1_macro = pooled_f1_macro\n",
    "    evaluation.pooled_f1_micro = pooled_f1_micro \n",
    "\n",
    "    evaluation.mean_acc        = mean(lst_accuracy)\n",
    "    evaluation.mean_f1_macro   = mean(lst_f1_macro)\n",
    "    evaluation.mean_f1_micro   = mean(lst_f1_micro)\n",
    "\n",
    "    evaluation.corr_l_acc      = np.corrcoef(lst_accuracy, seq_lengths)[0][0] # doubble zero indices due to output of numpy.corrcoef\n",
    "    evaluation.corr_l_f1_macro = np.corrcoef(lst_f1_macro, seq_lengths)[0][0]\n",
    "    evaluation.corr_l_f1_micro = np.corrcoef(lst_f1_micro, seq_lengths)[0][0]\n",
    "\n",
    "    evaluation.confusion       = confusion\n",
    "    evaluation.metrics_dict    = metrics_calc\n",
    "    \n",
    "    t2 = time.perf_counter()\n",
    "    passed_time = t2 - t1\n",
    "    print(\"Done! ({} m., {} s.)\".format(int(passed_time/60), int(passed_time%60)))\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [4, 4, 4, 4, 4, 8, 7, 13, 6, 6, 6, 4, 4, 4, 4, 4, 3]\n",
    "l2 = [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 3, 3, 3]\n",
    "f1_score(l1, l2, labels = [4, 8, 7], average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "srl_evaluation = evaluator(my_SRLLabeler, model_name, detach_me = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_evaluation.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_evaluation.print_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_evaluation.best_case(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_evaluation.best_cases(\"accuracy\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_evaluation.worst_case(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_evaluation.worst_cases(\"accuracy\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_evaluation.save(\"accuracy\")\n",
    "srl_evaluation.save(\"f1_macro\")\n",
    "srl_evaluation.save(\"f1_micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
