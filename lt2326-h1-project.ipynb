{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook contains the code for training and evaluating a Sequence to Sequence (seq2seq) Encoder - Decoder model for semantic role labeling (SRL), as project for the course LT2326, autumn 2021. Data preparation is defined and handled elsewhere; see `data_builder.ipynb`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On torchtext module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seemed to be no installation of `torchtext`, so I ran:\n",
    "\n",
    "```pip install torchtext==0.10.0```\n",
    "\n",
    "which shold be compatible with `torch` version 1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, time, operator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import torch.nn.functional as F\n",
    "#from torchtext.data import Field, BucketIterator, Iterator, TabularDataset\n",
    "from torchtext.legacy.data import Field, BucketIterator, Iterator, TabularDataset # Needed for running this on my laptop\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define where to get and store data and which device to use. For test pipline with less data during development set `mini_training`to `True`; when using complete dataset, set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\")\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "my_data_directory = \"../data/\" # MLTGPU\n",
    "\n",
    "my_models_directory = \"../models/\" #MLTGPU\n",
    "\n",
    "mini_testing = False\n",
    "my_train_file = \"mini_train.csv\" if mini_testing == True else \"train.csv\"\n",
    "my_test_file  = \"mini_test.csv\" if mini_testing == True else \"test.csv\"\n",
    "\n",
    "dir_for_evaluations = \"../evals/\" #MLTGPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(directory  = my_data_directory,\n",
    "               train_file = my_train_file,\n",
    "               test_file  = my_test_file,\n",
    "               batch      = batch_size):\n",
    "    \n",
    "    whitespacer = lambda x: x.split(\" \")\n",
    "    num_whitespacer = lambda x: [int(e) for e in x.split(\" \")]\n",
    "    \n",
    "    SENTENCE = Field(tokenize = whitespacer, \n",
    "                     lower = True,\n",
    "                     batch_first = True, \n",
    "                     init_token = \"<sos>\", \n",
    "                     eos_token = \"<eos>\")\n",
    "    \n",
    "    PREDICATE = Field(tokenize = num_whitespacer, # Here might be some problems ...\n",
    "                      batch_first = True, \n",
    "                      pad_token = 0,\n",
    "                      use_vocab = False,\n",
    "                      init_token = 0, \n",
    "                      eos_token = 0) \n",
    "    \n",
    "    SRLABEL = Field(batch_first = True, \n",
    "                    init_token = \"<sos>\", \n",
    "                    eos_token = \"<eos>\")\n",
    "    \n",
    "    my_fields = [(\"sentence\", SENTENCE),\n",
    "                 (\"predicate\", PREDICATE),\n",
    "                 (\"srlabel\", SRLABEL)]\n",
    "    \n",
    "    train, test = TabularDataset.splits(path   = directory,\n",
    "                                        train  = train_file,\n",
    "                                        test   = test_file,\n",
    "                                        format = 'csv',\n",
    "                                        fields = my_fields,\n",
    "                                        csv_reader_params = {'delimiter':'\\t',\n",
    "                                                             'quotechar':'Â¤'}) # Seems not to be in data\n",
    "    SENTENCE.build_vocab(train)\n",
    "    SRLABEL.build_vocab(train)  \n",
    "\n",
    "    train_iter, test_iter = BucketIterator.splits((train, test),\n",
    "                                                  batch_size        = batch,\n",
    "                                                  sort_within_batch = True,\n",
    "                                                  sort_key          = lambda x: len(x.sentence),\n",
    "                                                  shuffle           = True,\n",
    "                                                  device            = device)\n",
    "\n",
    "    return train_iter, test_iter, SENTENCE.vocab, SRLABEL.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, vocab, labels = dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=0\n",
    "for i, x in enumerate(test):\n",
    "    if x.sentence.shape != x.predicate.shape:\n",
    "        e += 1\n",
    "        print(\"ERROR:\", i)\n",
    "\n",
    "        print(\" \".join([vocab.itos[x] for x in x.sentence[0]]))\n",
    "        print(x.predicate)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder encodes sentence-predicate pairs through LSTMs. In forward pass, it returns *the final cell state* and *the final hidden state* (somtimes referred to as the *context vector*).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRL_Encoder(nn.Module):\n",
    "    def __init__(self, voc_size, embedding_size, hidden_size, n_layers, p_dropout):  \n",
    "        super(SRL_Encoder, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(voc_size, embedding_size)\n",
    "        self.sp_pair = embedding_size + 1 # emedded sentence + predicate vector\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.rnn = nn.LSTM(self.sp_pair, \n",
    "                           self.hidden_size, \n",
    "                           num_layers = self.n_layers,\n",
    "                           dropout = p_dropout,\n",
    "                           #bidirectional=True, # !\n",
    "                           batch_first=True) # !\n",
    "        self.dropout = nn.Dropout(p_dropout)\n",
    "        \n",
    "    def forward(self, sentences, pred_vec):\n",
    "        \n",
    "        embeddings = self.embeddings(sentences)\n",
    "        pred_vec = pred_vec.unsqueeze(2)        \n",
    "        sentence_pred_pair = torch.cat((embeddings, pred_vec), dim=2)\n",
    "        #print(sentence_pred_pair)\n",
    "        contextualized_embedding, (hidden_final, cell_final) = self.rnn(sentence_pred_pair)\n",
    "        \n",
    "        #print(\"ENC, hidden:\", hidden_final.shape)\n",
    "        #print(\"ENC, cell:\", cell_final.shape)\n",
    "        \n",
    "        return hidden_final, cell_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder predicts the next element of a sequence based on the previous sequence and the final cell state and the final hidden state of that sequence through an LSTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRL_Decoder(nn.Module):\n",
    "    def __init__(self, n_labels, embedding_size, hidden_size, n_layers, p_dropout):  \n",
    "        super(SRL_Decoder, self).__init__()\n",
    " \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "        self.embeddings = nn.Embedding(n_labels, embedding_size) # ?\n",
    "        self.rnn = nn.LSTM(embedding_size, \n",
    "                           self.hidden_size, \n",
    "                           num_layers = self.n_layers, \n",
    "                           batch_first=True,\n",
    "                           #bidirectional=True,\n",
    "                           dropout = p_dropout)\n",
    "        self.classifier = nn.Linear(hidden_size, self.n_labels)\n",
    "        \n",
    "    def forward(self, previous, hidden, cell):\n",
    "        \n",
    "        #previous = previous.unsqueeze(1)\n",
    "        \n",
    "        embedded = self.embeddings(previous)\n",
    "        #print(\"DEC, emb_previous:\", embedded.shape)\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.classifier(output)\n",
    "        \n",
    "        return prediction, hidden, cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder - Decoder Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `SRL_Seq2SeqLabeler`, the context vector (i.e. final cell and hidden states) of the `Encoder` together with the start token `<sos>` serves as inputs to predict a sequence of semantic role labels. After the first prediction, the decoder uses its own predictions as the input sequence to predict the next token. This model uses teacher forcing, meaning that, at some proportion of the time, as defined by a teacher force ratio (TFR), the true label of the sequence is put into the sequence, instead of the prediction by the encoder. \n",
    "\n",
    "Minor note: the classification problem engaged with here is a one-to-one mapping. Translation problems more generally might involve mappings of sequences of different lengths. To handle mappings of different lengths properly would require further work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRL_Seq2SeqLabeler(nn.Module):\n",
    "    def __init__(self, encoder, decoder):  \n",
    "        super(SRL_Seq2SeqLabeler, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        assert encoder.hidden_size == decoder.hidden_size, \"hidden dimension of encoder must be equal to that of decoder\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \"n_layers of encoder must be equal to that of decoder\"\n",
    "        \n",
    "    def forward(self, sentence, predicate, srl_labels, tfr = None): # tfr = teacher forcing ratio\n",
    "\n",
    "        batch_size = sentence.shape[0]\n",
    "        seq_len = sentence.shape[1]\n",
    "        n_labels = self.decoder.n_labels\n",
    "\n",
    "        outputs = torch.zeros(batch_size, seq_len, n_labels).to(device) # for storage\n",
    "\n",
    "        hidden, cell = self.encoder(sentence, predicate)\n",
    "\n",
    "        seq_element = srl_labels[:, 0].unsqueeze(1) # start of sentence token; index of <sos>\n",
    "        #print(\"S2S, Seq_elem, prior:\", seq_element)\n",
    "\n",
    "        for l in range(1, seq_len): # Note: starts from 1; first column of outputs will \"remain\" 0\n",
    "            \n",
    "            #print(\"S2S, Seq_elem:\", seq_element.shape)\n",
    "\n",
    "            output, hidden, cell = self.decoder(seq_element, hidden, cell)\n",
    "            #print(\"S2S, Outputs:\", outputs.shape)\n",
    "            #print(\"S2S, Output:\", output.shape)\n",
    "            outputs[:, l, :] = output.squeeze()\n",
    "            best_guess = output.argmax(2)\n",
    "            #print(\"S2S, Best guess:\", best_guess)\n",
    "\n",
    "            if tfr != None:\n",
    "                teacher_force = random.random() < tfr\n",
    "#                 if teacher_force:\n",
    "#                     print(\"TF\")\n",
    "#                 else:\n",
    "#                     print(\"No TF\")\n",
    "                seq_element = srl_labels[:, l].unsqueeze(1) if teacher_force else best_guess\n",
    "            else:\n",
    "                seq_element = best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, # Must be an instance of a model!\n",
    "            name_of_model,\n",
    "            learning_rate,\n",
    "            epochs,\n",
    "            data,\n",
    "            my_tfr = 0.5,\n",
    "            clip_grad = None,\n",
    "            val_data = None,\n",
    "            save_model = False,\n",
    "            directory = my_models_directory,\n",
    "            my_loss_function = nn.CrossEntropyLoss,\n",
    "            my_optimizer = optim.Adam\n",
    "           ):\n",
    "    \"\"\" Specifices a general training procedure for a model. \n",
    "        Note: trainer() requires an instantiated model as model argument.\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer = my_optimizer(model.parameters(), lr=learning_rate)    \n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    pad_idx = labels.stoi[\"<pad>\"]\n",
    "    \n",
    "    loss_function = my_loss_function(ignore_index=pad_idx) # We ignore pad token in loss calculation\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch+1} (out of {epochs}).\")\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for i, batch in enumerate(data):\n",
    "            print(\"Batch: \", i, end=\"\\r\")\n",
    "            optimizer.zero_grad # reset gradients\n",
    "            \n",
    "            sentence = batch.sentence\n",
    "            predicate = batch.predicate\n",
    "            targets = batch.srlabel\n",
    "            #print(\"TRAIN, Targets:\", targets.shape)\n",
    "            \n",
    "            output = model(sentence, predicate, targets, tfr = my_tfr)\n",
    "            #print(\"TRAIN, Output:\", output.shape)\n",
    "            \n",
    "            # Before calculation of loss outputs and targets needs to be \"aligned\", so to speak.\n",
    "            # Outputs are of shape [batch, seq_len, dimension]. Targets of shape [batch, seq_len]\n",
    "            # The representation of the first element of the output sequence will be 0s (see \n",
    "            # above). The first element of the targets will be <sos>. We ignore these first elements\n",
    "            # in calculating the loss. \n",
    "            \n",
    "            # Moreover, our loss function (CrossEntropyLoss) expects predicitons as [n_predictions, \n",
    "            # n_classes] and targets as [n_predictions]. Here, n_predictions = batch_size * sequence_\n",
    "            # length. \n",
    "            \n",
    "            bsz = output.shape[0]\n",
    "            length = output.shape[1]\n",
    "            output_dim = output.shape[2]\n",
    "        \n",
    "            output = output[:, 1:, :].reshape(bsz*(length - 1), output_dim) # first token (\"column\") being zeroes\n",
    "            targets = targets[:, 1:].flatten() # first token being <sos>\n",
    "            \n",
    "            # Now, calculate the loss\n",
    "            loss = loss_function(output, targets)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            if clip_grad != None:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), clip_grad) # to handle exploding gradients\n",
    "            \n",
    "            loss.backward() # compute gradients\n",
    "            optimizer.step() # update parameters\n",
    "            #break\n",
    "            \n",
    "        print(f\"Total loss for Epoch {epoch+1}: {epoch_loss}.\")\n",
    "        print()\n",
    "            \n",
    "        if val_data != None:\n",
    "            model.eval()\n",
    "            # Here we could do some evaluation of model progress, but I have ignored this for now. \n",
    "            model.train()\n",
    "            \n",
    "    if save_model == True:\n",
    "        torch.save(model, directory+name_of_model+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples from the web:\n",
    "\n",
    "|Author            |No. of layers|Batch Size|Embeddingsdim.|Hidden Dim.|Dropout|WWW             |\n",
    "|------------------|-------------|----------|--------------|-----------|-------|---------|\n",
    "|Ziqi Yuan         |            2|       128|           256|        512|    0.5|https://www.kaggle.com/columbine/seq2seq-pytorch|\n",
    "|Balakrishnakumar V|            2|        32|           300|       1024|    0.5|https://towardsdatascience.com/a-comprehensive-guide-to-neural-machine-translation-using-seq2sequence-modelling-using-pytorch-41c9b84ba350|\n",
    "|Matthew Inkawhich |            2|        64|           ?  |        500|    0.1|https://pytorch.org/tutorials/beginner/deploy_seq2seq_hybrid_frontend_tutorial.html|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_epochs = 20\n",
    "learning_rate = 0.005\n",
    "# batch size defined before calling dataloader\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "num_labels = len(labels)\n",
    "emb_sizeE = 512\n",
    "emb_sizeD = num_labels\n",
    "#emb_sizeD = int(num_labels/2) # embeddings for labels\n",
    "hid_size_encoder = 512\n",
    "hid_size_decoder = hid_size_encoder # ?\n",
    "\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_encoder = SRL_Encoder(vocab_size, emb_sizeE, hid_size_encoder, num_layers, p_dropout=0.1)\n",
    "my_decoder = SRL_Decoder(num_labels, emb_sizeD, hid_size_decoder, num_layers, p_dropout=0.1)\n",
    "my_SRLLabeler = SRL_Seq2SeqLabeler(my_encoder, my_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Know your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of SRL_Encoder(\n",
       "  (embeddings): Embedding(34068, 512)\n",
       "  (rnn): LSTM(513, 512, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_encoder.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of SRL_Decoder(\n",
       "  (embeddings): Embedding(87, 87)\n",
       "  (rnn): LSTM(87, 512, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (classifier): Linear(in_features=512, out_features=87, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_decoder.parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_name = f\"srl_b{batch_size}_e{my_epochs}_minisample\" if mini_testing else f\"srl_b{batch_size}_e{my_epochs}_csample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (out of 20).\n",
      "Total loss for Epoch 1: 58025.625101327896.\n",
      "\n",
      "Epoch: 2 (out of 20).\n",
      "Total loss for Epoch 2: 109161.95507240295.\n",
      "\n",
      "Epoch: 3 (out of 20).\n",
      "Total loss for Epoch 3: 159074.84688568115.\n",
      "\n",
      "Epoch: 4 (out of 20).\n",
      "Total loss for Epoch 4: 158834.90034484863.\n",
      "\n",
      "Epoch: 5 (out of 20).\n",
      "Total loss for Epoch 5: 104778.5583820343.\n",
      "\n",
      "Epoch: 6 (out of 20).\n",
      "Total loss for Epoch 6: 78559.63410186768.\n",
      "\n",
      "Epoch: 7 (out of 20).\n",
      "Total loss for Epoch 7: 72304.06441020966.\n",
      "\n",
      "Epoch: 8 (out of 20).\n",
      "Total loss for Epoch 8: 79639.44922733307.\n",
      "\n",
      "Epoch: 9 (out of 20).\n",
      "Total loss for Epoch 9: 73400.72047424316.\n",
      "\n",
      "Epoch: 10 (out of 20).\n",
      "Total loss for Epoch 10: 77918.80178546906.\n",
      "\n",
      "Epoch: 11 (out of 20).\n",
      "Total loss for Epoch 11: 82208.77340888977.\n",
      "\n",
      "Epoch: 12 (out of 20).\n",
      "Total loss for Epoch 12: 91725.817984581.\n",
      "\n",
      "Epoch: 13 (out of 20).\n",
      "Total loss for Epoch 13: 81651.45838069916.\n",
      "\n",
      "Epoch: 14 (out of 20).\n",
      "Total loss for Epoch 14: 90009.67163181305.\n",
      "\n",
      "Epoch: 15 (out of 20).\n",
      "Total loss for Epoch 15: 96756.93361854553.\n",
      "\n",
      "Epoch: 16 (out of 20).\n",
      "Total loss for Epoch 16: 87945.01739501953.\n",
      "\n",
      "Epoch: 17 (out of 20).\n",
      "Total loss for Epoch 17: 87349.46957588196.\n",
      "\n",
      "Epoch: 18 (out of 20).\n",
      "Total loss for Epoch 18: 90246.4350566864.\n",
      "\n",
      "Epoch: 19 (out of 20).\n",
      "Total loss for Epoch 19: 97049.19098854065.\n",
      "\n",
      "Epoch: 20 (out of 20).\n",
      "Total loss for Epoch 20: 95024.46664142609.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer(model = my_SRLLabeler, \n",
    "        name_of_model = model_name, \n",
    "        learning_rate = learning_rate, \n",
    "        epochs = my_epochs, \n",
    "        data = train, \n",
    "        save_model = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation, several functions are defined. Also, a class for managing information from evalution is defined. Overall, the model is evaluated by\n",
    "*    its accuracy (number of correct predictions / total)\n",
    "*    F1 averaged globally\n",
    "*    F1 averaged by mean\n",
    "*    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of labels\n",
    "lst_labels = [labels.itos[x] for x in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " '<sos>',\n",
       " '<eos>',\n",
       " 'O',\n",
       " 'I-ARG1',\n",
       " 'I-ARG2',\n",
       " 'B-PRD',\n",
       " 'B-ARG1',\n",
       " 'I-ARG0',\n",
       " 'I-ARGM-ADV',\n",
       " 'B-ARG0',\n",
       " 'I-ARGM-TMP',\n",
       " 'I-ARGM-LOC',\n",
       " 'B-ARG2',\n",
       " 'I-ARGM-MNR',\n",
       " 'I-ARGM-PRP',\n",
       " 'B-ARGM-TMP',\n",
       " 'B-ARGM-MOD',\n",
       " 'B-ARGM-ADV',\n",
       " 'I-ARGM-CAU',\n",
       " 'B-ARGM-MNR',\n",
       " 'B-ARGM-LOC',\n",
       " 'I-ARG3',\n",
       " 'I-C-ARG1',\n",
       " 'I-ARGM-ADJ',\n",
       " 'B-ARGM-DIS',\n",
       " 'B-ARGM-NEG',\n",
       " 'I-R-ARG0',\n",
       " 'I-ARG4',\n",
       " 'I-ARGM-DIR',\n",
       " 'B-ARGM-PRP',\n",
       " 'B-R-ARG0',\n",
       " 'B-R-ARG1',\n",
       " 'I-ARGM-PRD',\n",
       " 'B-ARGM-ADJ',\n",
       " 'B-ARGM-DIR',\n",
       " 'I-ARGM-DIS',\n",
       " 'B-ARG3',\n",
       " 'B-ARGM-CAU',\n",
       " 'I-ARGM-GOL',\n",
       " 'I-ARGM-PNC',\n",
       " 'B-ARGM-EXT',\n",
       " 'B-ARG4',\n",
       " 'I-R-ARG1',\n",
       " 'B-R-ARGM-LOC',\n",
       " 'I-ARGM-COM',\n",
       " 'B-ARGM-PRD',\n",
       " 'B-ARGM-LVB',\n",
       " 'B-C-ARG1',\n",
       " 'I-ARGM-EXT',\n",
       " 'I-C-ARG2',\n",
       " 'B-ARGM-GOL',\n",
       " 'B-R-ARGM-TMP',\n",
       " 'B-R-ARG2',\n",
       " 'B-ARGM-COM',\n",
       " 'I-R-ARGM-LOC',\n",
       " 'B-ARGM-PNC',\n",
       " 'B-R-ARGM-MNR',\n",
       " 'I-R-ARGM-MNR',\n",
       " 'B-ARGM-REC',\n",
       " 'I-R-ARG2',\n",
       " 'I-C-ARGM-MNR',\n",
       " 'B-C-ARG2',\n",
       " 'I-ARGM-NEG',\n",
       " 'I-C-ARGM-LOC',\n",
       " 'I-R-ARGM-TMP',\n",
       " 'B-R-ARGM-CAU',\n",
       " 'B-R-ARG3',\n",
       " 'I-R-ARG3',\n",
       " 'B-R-ARGM-GOL',\n",
       " 'I-R-ARGM-GOL',\n",
       " 'B-R-ARGM-DIR',\n",
       " 'I-C-ARGM-ADV',\n",
       " 'I-C-ARGM-EXT',\n",
       " 'I-R-ARGM-DIR',\n",
       " 'B-C-ARGM-LOC',\n",
       " 'B-C-ARGM-MNR',\n",
       " 'I-C-ARG0',\n",
       " 'I-R-ARGM-CAU',\n",
       " 'B-C-ARG0',\n",
       " 'B-C-ARGM-ADV',\n",
       " 'B-C-ARGM-EXT',\n",
       " 'B-R-ARGM-ADV',\n",
       " 'B-R-ARGM-COM',\n",
       " 'I-R-ARGM-ADV',\n",
       " 'I-R-ARGM-COM']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_labels #remove stuff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and a class for handling information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCES:\n",
    "# https://www.baeldung.com/cs/multi-class-f1-score\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "\n",
    "def metrics(prediction, \n",
    "            truth \n",
    "            #labels = lst_labels\n",
    "           ):\n",
    "    \"\"\" Calculates accuracy and F1, given two sequences (lists, arrays) of labels. Since, \n",
    "        these metrices here are calculated for multi-label classification, two versions \n",
    "        of F1 are calculated: \"macro\" and \"micro\", where the former is the mean of F1 for\n",
    "        each label, and the latter is calculated globally by counting the total true \n",
    "        positives, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    #print(prediction, len(prediction))\n",
    "    #print(truth, len(truth))\n",
    "    \n",
    "    \n",
    "    #f1_dict = {}\n",
    "    \n",
    "    accuracy = accuracy_score(truth, prediction)\n",
    "    #f1_lsted = f1_score(truth, prediction, labels = labels, average = None, zero_division = 0)\n",
    "    f1_macro = f1_score(truth, prediction, average = \"macro\") # Calculate metrics for each label, and find their unweighted mean. Does not take label imbalance into account.\n",
    "    f1_micro = f1_score(truth, prediction, average = \"micro\") # Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "    \n",
    "#    for label in labels:\n",
    "#        f1_dict[label] = f1_lsted[labels.index(label)] # overkill?\n",
    "\n",
    "    return accuracy, f1_macro, f1_micro\n",
    "#    return accuracy, f1_macro, f1_micro, f1_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(array):\n",
    "    \"\"\" Calculates the mean and standard deviation of an aray of numbers.\n",
    "    \"\"\"\n",
    "    mean = np.mean(array)\n",
    "    std  = np.std(array)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    \"\"\" For storing and handling information from the evaluation of model(s).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "        self.pooled_acc      = \"Not yet defined\"\n",
    "        self.pooled_f1_macro = \"Not yet defined\"\n",
    "        self.pooled_f1_micro = \"Not yet defined\" \n",
    "        \n",
    "        self.mean_acc        = (\"Not yet defined\", \"Not yet defined\")\n",
    "        self.mean_f1_macro   = (\"Not yet defined\", \"Not yet defined\")\n",
    "        self.mean_f1_micro   = (\"Not yet defined\", \"Not yet defined\")\n",
    "        \n",
    "        self.corr_l_acc      = \"Not yet defined\"\n",
    "        self.corr_l_f1_macro = \"Not yet defined\"\n",
    "        self.corr_l_f1_micro = \"Not yet defined\"\n",
    "        \n",
    "        self.confusion = {\"Not yet defined\": {\"Not yet defined\": \"Not yet defined\"}}\n",
    "        self.metrics_dict = {\"accuracy\": [\"Not yet defined\", \"Not yet defined\"], \n",
    "                             \"f1_macro\": [\"Not yet defined\", \"Not yet defined\"], \n",
    "                             \"f1_micro\": [\"Not yet defined\", \"Not yet defined\"]}\n",
    "\n",
    "    def best_case(self, metric):\n",
    "        \"\"\" Returns the file which has the best performance score with respect \n",
    "            to a metric.\n",
    "        \"\"\"\n",
    "        m_list = self.metrics_dict[metric]\n",
    "        zic_zac = False if metric == \"mse\" else True\n",
    "        m_list.sort(key=operator.itemgetter(1), reverse=zic_zac)\n",
    "        return m_list[0][0]\n",
    "    \n",
    "    def best_cases(self, metric, n):\n",
    "        \"\"\" Returns a list of the N files which has the best performance score \n",
    "            with respect to a metric.\n",
    "        \"\"\"\n",
    "        m_list = self.metrics_dict[metric]\n",
    "        zic_zac = False if metric == \"mse\" else True\n",
    "        m_list.sort(key=operator.itemgetter(1), reverse=zic_zac)\n",
    "        files, values = zip(*m_list)\n",
    "        return list(files[:n])\n",
    "    \n",
    "    def worst_case(self, metric):\n",
    "        \"\"\" Returns the file which has the best performance score with respect \n",
    "            to a metric.\n",
    "        \"\"\"\n",
    "        m_list = self.metrics_dict[metric]\n",
    "        zic_zac = True if metric == \"mse\" else False\n",
    "        m_list.sort(key=operator.itemgetter(1), reverse=zic_zac)\n",
    "        return m_list[0][0]\n",
    "\n",
    "    def worst_cases(self, metric, n):\n",
    "        \"\"\" Returns a list of the N files which has the best performance score \n",
    "            with respect to a metric.\n",
    "        \"\"\"\n",
    "        m_list = self.metrics_dict[metric]\n",
    "        zic_zac = True if metric == \"mse\" else False\n",
    "        m_list.sort(key=operator.itemgetter(1), reverse=zic_zac)\n",
    "        files, values = zip(*m_list)\n",
    "        return list(files[:n])\n",
    " \n",
    "    def summary(self):\n",
    "        \"\"\" Summarises an evaluation. Returns string.\"\"\"\n",
    "        summary  = \"\\n\".join([f\"Model {self.name} performs as follows:\", \n",
    "                      f\"Pooled Accuracy: {self.pooled_acc}\",\n",
    "                      f\"Pooled F1_macro: {self.pooled_f1_macro}\",\n",
    "                      f\"Pooled F1_micro: {self.pooled_f1_micro}\",\n",
    "                              \n",
    "                      f\"Mean Accuracy: {self.mean_acc[0]} (std = {self.mean_acc[1]})\",\n",
    "                      f\"Mean F1_macro: {self.mean_f1_macro[0]} (std = {self.mean_f1_macro[1]})\",\n",
    "                      f\"Mean F1_micro: {self.mean_f1_micro[0]} (std = {self.mean_f1_micro[1]})\",\n",
    "                      \n",
    "                      f\"Correlation sentence length and accuracy: {self.corr_l_acc}\",\n",
    "                      f\"Correlation sentence length and F1_macro: {self.corr_l_f1_macro}\",\n",
    "                      f\"Correlation sentence length and F1_micro: {self.corr_l_f1_micro}\"]) \n",
    "        return summary\n",
    "    \n",
    "    def confusion_matrix(self):\n",
    "        \"\"\" Returns and prints a confusion matrix. \n",
    "        \"\"\"\n",
    "        \n",
    "        srl_labels = list(self.confusion.keys())\n",
    "        \n",
    "        matrix = [[\"\"] + srl_labels] # headings\n",
    "        for l in srl_labels:\n",
    "            row = [l]\n",
    "            for k in srl_labels:\n",
    "                row.append(str(self.confusion[l][k]))\n",
    "            matrix.append(row)\n",
    "            \n",
    "        #matrix_txt = [[str(cell) for cell in row] for row in matrix]\n",
    "        \n",
    "        txt = \"\\n\".join([\"\\t\".join(row) for row in matrix])\n",
    "        \n",
    "        #print(txt)\n",
    "        return txt\n",
    "    \n",
    "    def save(self, metric, directory=dir_for_evaluations):\n",
    "        \"\"\" Writes the summary of an evaluation to a text file (at some diectory).\"\"\"\n",
    "        \n",
    "        summary = self.summary()\n",
    "        confusion_matrix = self.confusion_matrix()\n",
    "        best_sentences = \"\\n\".join([f\"Best sentences ({metric}):\"] + self.best_cases(metric, 5))\n",
    "        worst_sentences = \"\\n\".join([f\"Worst sentences ({metric}):\"] + self.worst_cases(metric, 5))\n",
    "        \n",
    "        output_to_save = summary + \"\\n\" + confusion_matrix + \"\\n\" + best_sentences + \"\\n\" + worst_sentences\n",
    "        \n",
    "        with open(f\"{directory}{self.name}_{metric}.txt\", \"w\") as e:\n",
    "            e.write(output_to_save)\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\" Prints out the summary of an evaluation.\n",
    "        \"\"\"\n",
    "        summary = self.summary()\n",
    "        print(summary)\n",
    "        \n",
    "    def print_confusion_matrix(self):\n",
    "        \"\"\" Prints out the confusion matrix.\n",
    "        \"\"\"\n",
    "        c_matrix = self.confusion_matrix()\n",
    "        print(c_matrix)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(model, name, test_data = test, srl_labels = lst_labels, detach_me=False):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    t1 = time.perf_counter()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    evaluation = Evaluation(name)\n",
    "    \n",
    "    prediction_pooled = [] # to collect all predictions\n",
    "    truth_pooled = []      # to collect all true labels\n",
    "    seq_lengths = []       # to collect the length of sentences\n",
    "    confusion = {label: {label: 0 for label in srl_labels} for label in srl_labels} # for confusion matrix\n",
    "    metrics_calc = {\"accuracy\": [], \"f1_macro\": [], \"f1_micro\": []} # to collect accuracy and f1 for every sentence\n",
    "    \n",
    "    #i=1 # in order to print out progress\n",
    "    for batch in test_data:\n",
    "        sentence = batch.sentence\n",
    "        predicate = batch.predicate\n",
    "        truth = batch.srlabel\n",
    "        \n",
    "        \n",
    "            \n",
    "        if detach_me == True: # to avoid some CUDA memory shortage issues\n",
    "            prediction = model(sentence, predicate, truth).detach().to(\"cpu\")\n",
    "            truth = batch.srlabel.detach().to(\"cpu\")\n",
    "        \n",
    "        else:\n",
    "            prediction = model(sentence, predicate, truth) \n",
    "        \n",
    "        batched_pred_labels = prediction[:, 1:, :].argmax(2) # ... should not be batch-wise, but sentence-wise\n",
    "        batched_true_labels = truth[:, 1:]\n",
    "        \n",
    "        bsz = batched_pred_labels.shape[0]\n",
    "        \n",
    "        for b in range(bsz):\n",
    "            str_sent    = \" \".join([vocab.itos[token] for token in sentence[b]]) # to list?\n",
    "            seq_len     = len([x for x in sentence[b] if vocab.itos[x] not in [\"<pad>\", \"<sos>\", \"<eos>\"]])\n",
    "            pred_labels = batched_pred_labels[b].tolist()\n",
    "            true_labels = batched_true_labels[b].tolist()\n",
    "            \n",
    "            #accuracy, f1_macro, f1_micro, X = metrics(true_labels, pred_labels)\n",
    "            accuracy, f1_macro, f1_micro = metrics(true_labels, pred_labels)\n",
    "            \n",
    "            prediction_pooled.extend(pred_labels)\n",
    "            truth_pooled.extend(true_labels)\n",
    "            seq_lengths.append(seq_len)\n",
    "            \n",
    "            for p, t in zip(pred_labels, true_labels):\n",
    "                confusion[srl_labels[p]][srl_labels[t]] += 1\n",
    "                \n",
    "            for m, v in zip([\"accuracy\", \"f1_macro\", \"f1_micro\"], [accuracy, f1_macro, f1_micro]):\n",
    "                metrics_calc[m].append( (str_sent, v) )\n",
    "    \n",
    "    #print(prediction_pooled)\n",
    "    \n",
    "    #pooled_accuracy, pooled_f1_macro, pooled_f1_micro, X = metrics(truth_pooled, prediction_pooled)\n",
    "    pooled_accuracy, pooled_f1_macro, pooled_f1_micro = metrics(truth_pooled, prediction_pooled)\n",
    "\n",
    "    lst_accuracy = list(zip(*metrics_calc[\"accuracy\"]))[1]\n",
    "    lst_f1_macro = list(zip(*metrics_calc[\"f1_macro\"]))[1]\n",
    "    lst_f1_micro = list(zip(*metrics_calc[\"f1_micro\"]))[1]\n",
    "\n",
    "    evaluation.pooled_acc      = pooled_accuracy\n",
    "    evaluation.pooled_f1_macro = pooled_f1_macro\n",
    "    evaluation.pooled_f1_micro = pooled_f1_micro \n",
    "\n",
    "    evaluation.mean_acc        = mean(lst_accuracy)\n",
    "    evaluation.mean_f1_macro   = mean(lst_f1_macro)\n",
    "    evaluation.mean_f1_micro   = mean(lst_f1_micro)\n",
    "    \n",
    "    evaluation.corr_l_acc      = np.corrcoef(lst_accuracy, seq_lengths)[0][1] # double zero indices due to output of numpy.corrcoef\n",
    "    evaluation.corr_l_f1_macro = np.corrcoef(lst_f1_macro, seq_lengths)[0][1]\n",
    "    evaluation.corr_l_f1_micro = np.corrcoef(lst_f1_micro, seq_lengths)[0][1]\n",
    "\n",
    "    evaluation.confusion       = confusion\n",
    "    evaluation.metrics_dict    = metrics_calc\n",
    "    \n",
    "    t2 = time.perf_counter()\n",
    "    passed_time = t2 - t1\n",
    "    print(\"Done! ({} m., {} s.)\".format(int(passed_time/60), int(passed_time%60)))\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [4, 4, 4, 4, 4, 8, 7, 13, 6, 6, 6, 4, 4, 4, 4, 4, 3]\n",
    "l2 = [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 3, 3, 3]\n",
    "f1_score(l1, l2, labels = [4, 8, 7], average = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.40618785]\n",
      " [0.40618785 1.        ]]\n",
      "Done! (1 m., 7 s.)\n"
     ]
    }
   ],
   "source": [
    "srl_evaluation = evaluator(my_SRLLabeler, model_name, detach_me = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model srl_b64_e20_csample performs as follows:\n",
      "Pooled Accuracy: 0.6182829261082977\n",
      "Pooled F1_macro: 0.01728717682283431\n",
      "Pooled F1_micro: 0.6182829261082977\n",
      "Mean Accuracy: 0.517132622970087 (std = 0.3101600846643508)\n",
      "Mean F1_macro: 0.12659429455295784 (std = 0.09527505764212267)\n",
      "Mean F1_micro: 0.517132622970087 (std = 0.3101600846643508)\n",
      "Correlation sentence length and accuracy: 0.4061878468084584\n",
      "Correlation sentence length and F1_macro: -0.0013897933574972025\n",
      "Correlation sentence length and F1_micro: 0.4061878468084584\n"
     ]
    }
   ],
   "source": [
    "srl_evaluation.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t<unk>\t<pad>\t<sos>\t<eos>\tO\tI-ARG1\tI-ARG2\tB-PRD\tB-ARG1\tI-ARG0\tI-ARGM-ADV\tB-ARG0\tI-ARGM-TMP\tI-ARGM-LOC\tB-ARG2\tI-ARGM-MNR\tI-ARGM-PRP\tB-ARGM-TMP\tB-ARGM-MOD\tB-ARGM-ADV\tI-ARGM-CAU\tB-ARGM-MNR\tB-ARGM-LOC\tI-ARG3\tI-C-ARG1\tI-ARGM-ADJ\tB-ARGM-DIS\tB-ARGM-NEG\tI-R-ARG0\tI-ARG4\tI-ARGM-DIR\tB-ARGM-PRP\tB-R-ARG0\tB-R-ARG1\tI-ARGM-PRD\tB-ARGM-ADJ\tB-ARGM-DIR\tI-ARGM-DIS\tB-ARG3\tB-ARGM-CAU\tI-ARGM-GOL\tI-ARGM-PNC\tB-ARGM-EXT\tB-ARG4\tI-R-ARG1\tB-R-ARGM-LOC\tI-ARGM-COM\tB-ARGM-PRD\tB-ARGM-LVB\tB-C-ARG1\tI-ARGM-EXT\tI-C-ARG2\tB-ARGM-GOL\tB-R-ARGM-TMP\tB-R-ARG2\tB-ARGM-COM\tI-R-ARGM-LOC\tB-ARGM-PNC\tB-R-ARGM-MNR\tI-R-ARGM-MNR\tB-ARGM-REC\tI-R-ARG2\tI-C-ARGM-MNR\tB-C-ARG2\tI-ARGM-NEG\tI-C-ARGM-LOC\tI-R-ARGM-TMP\tB-R-ARGM-CAU\tB-R-ARG3\tI-R-ARG3\tB-R-ARGM-GOL\tI-R-ARGM-GOL\tB-R-ARGM-DIR\tI-C-ARGM-ADV\tI-C-ARGM-EXT\tI-R-ARGM-DIR\tB-C-ARGM-LOC\tB-C-ARGM-MNR\tI-C-ARG0\tI-R-ARGM-CAU\tB-C-ARG0\tB-C-ARGM-ADV\tB-C-ARGM-EXT\tB-R-ARGM-ADV\tB-R-ARGM-COM\tI-R-ARGM-ADV\tI-R-ARGM-COM\n",
      "<unk>\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "<pad>\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "<sos>\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "<eos>\t0\t23\t0\t3698\t1692\t244\t92\t82\t45\t56\t36\t22\t24\t23\t31\t8\t10\t15\t7\t3\t4\t13\t6\t4\t5\t4\t2\t2\t3\t3\t3\t1\t4\t3\t2\t1\t0\t1\t2\t0\t1\t0\t1\t1\t1\t1\t0\t1\t1\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "O\t16\t5805\t0\t11787\t618468\t67307\t26350\t18205\t15108\t12922\t8151\t7054\t7286\t5907\t5138\t4346\t4014\t2608\t1940\t1455\t1672\t1607\t1468\t846\t887\t725\t508\t608\t489\t629\t557\t470\t498\t429\t390\t268\t266\t193\t247\t186\t166\t208\t153\t170\t102\t133\t115\t98\t63\t91\t73\t9\t42\t37\t33\t33\t44\t28\t32\t27\t15\t10\t0\t1\t4\t0\t7\t6\t7\t7\t1\t1\t0\t4\t0\t0\t0\t0\t6\t0\t2\t1\t0\t0\t0\t0\t0\n",
      "I-ARG1\t0\t785\t0\t3998\t93831\t12029\t4815\t3765\t2950\t2992\t1752\t1274\t1390\t1213\t1054\t839\t846\t481\t411\t252\t270\t307\t267\t217\t197\t133\t92\t159\t147\t135\t50\t80\t76\t108\t84\t43\t36\t59\t46\t29\t9\t66\t29\t35\t21\t22\t11\t19\t13\t19\t4\t3\t1\t4\t7\t7\t2\t6\t5\t5\t0\t5\t0\t1\t0\t0\t2\t1\t1\t1\t2\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARG2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-PRD\t0\t24\t0\t4\t7881\t852\t54\t481\t344\t704\t218\t323\t176\t102\t24\t31\t60\t66\t87\t42\t13\t26\t12\t0\t0\t0\t34\t8\t41\t0\t4\t1\t7\t2\t7\t8\t2\t71\t0\t2\t2\t0\t2\t6\t6\t0\t0\t1\t9\t0\t0\t0\t1\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARG1\t0\t0\t0\t0\t8379\t7\t1\t181\t1085\t0\t0\t1217\t1\t1\t72\t0\t1\t244\t4\t244\t0\t44\t104\t0\t0\t0\t259\t5\t1\t0\t0\t62\t39\t5\t0\t2\t4\t0\t0\t21\t0\t0\t0\t0\t0\t0\t0\t8\t1\t0\t0\t0\t2\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARG0\t0\t0\t0\t0\t276\t26\t3\t22\t14\t12\t2\t3\t6\t3\t2\t0\t0\t3\t5\t1\t0\t1\t0\t0\t0\t0\t1\t1\t2\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-ADV\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARG0\t0\t0\t0\t0\t497\t0\t0\t17\t52\t0\t0\t58\t0\t0\t7\t0\t0\t14\t2\t8\t0\t1\t4\t0\t0\t0\t14\t0\t0\t0\t0\t0\t6\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-TMP\t0\t316\t0\t58\t710\t130\t32\t31\t24\t47\t7\t21\t11\t5\t5\t5\t4\t4\t8\t1\t2\t4\t3\t0\t0\t4\t2\t2\t0\t0\t0\t1\t0\t1\t0\t0\t1\t6\t0\t1\t0\t0\t1\t0\t1\t1\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-LOC\t0\t0\t0\t1\t508\t69\t10\t26\t22\t11\t19\t11\t5\t12\t6\t0\t3\t7\t3\t2\t0\t0\t1\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARG2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-MNR\t0\t4\t0\t0\t214\t15\t10\t4\t4\t2\t3\t4\t4\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-PRP\t0\t0\t0\t0\t3\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-TMP\t0\t150\t0\t207\t90\t8\t3\t3\t0\t6\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-MOD\t0\t0\t0\t0\t5\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-ADV\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-CAU\t0\t510\t0\t337\t9207\t592\t259\t149\t120\t103\t91\t39\t49\t62\t49\t28\t53\t14\t10\t16\t1\t13\t13\t3\t10\t1\t3\t7\t0\t0\t0\t7\t2\t1\t0\t3\t0\t0\t1\t0\t0\t7\t0\t0\t0\t1\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-MNR\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-LOC\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARG3\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-C-ARG1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-ADJ\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-DIS\t0\t1183\t0\t2550\t920\t67\t26\t24\t20\t17\t14\t8\t12\t7\t6\t2\t8\t4\t9\t2\t2\t3\t1\t2\t0\t0\t0\t4\t1\t0\t2\t0\t0\t1\t2\t1\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-NEG\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-R-ARG0\t0\t0\t0\t0\t47\t4\t0\t2\t2\t3\t2\t0\t2\t0\t2\t1\t1\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARG4\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-DIR\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-PRP\t0\t0\t0\t1\t254\t43\t9\t15\t15\t9\t3\t15\t2\t5\t1\t0\t0\t5\t3\t3\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\t0\t0\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-R-ARG0\t0\t0\t0\t0\t5\t0\t0\t1\t2\t0\t0\t3\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-R-ARG1\t0\t0\t0\t1\t111\t19\t4\t8\t5\t9\t4\t3\t0\t0\t3\t0\t1\t2\t1\t1\t0\t3\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-PRD\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-ADJ\t0\t344\t0\t366\t90\t9\t4\t3\t1\t0\t0\t1\t0\t0\t0\t1\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-DIR\t0\t2\t0\t16\t193\t43\t9\t9\t9\t8\t7\t3\t4\t0\t0\t2\t0\t2\t3\t0\t1\t0\t0\t0\t0\t1\t0\t0\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-DIS\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARG3\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-CAU\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-GOL\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-PNC\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-EXT\t0\t0\t0\t3\t11\t4\t4\t0\t0\t0\t1\t1\t0\t1\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARG4\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-R-ARG1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-R-ARGM-LOC\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-COM\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-PRD\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-LVB\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-C-ARG1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-EXT\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-C-ARG2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-GOL\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-R-ARGM-TMP\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-R-ARG2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-COM\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-R-ARGM-LOC\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-PNC\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-R-ARGM-MNR\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-R-ARGM-MNR\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-ARGM-REC\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-R-ARG2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-C-ARGM-MNR\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-C-ARG2\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-ARGM-NEG\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-C-ARGM-LOC\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-R-ARGM-TMP\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-R-ARGM-CAU\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-R-ARG3\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-R-ARG3\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-R-ARGM-GOL\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-R-ARGM-GOL\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-R-ARGM-DIR\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-C-ARGM-ADV\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-C-ARGM-EXT\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-R-ARGM-DIR\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-C-ARGM-LOC\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-C-ARGM-MNR\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-C-ARG0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-R-ARGM-CAU\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-C-ARG0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-C-ARGM-ADV\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-C-ARGM-EXT\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-R-ARGM-ADV\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "B-R-ARGM-COM\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-R-ARGM-ADV\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
      "I-R-ARGM-COM\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n"
     ]
    }
   ],
   "source": [
    "srl_evaluation.print_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<sos> aop urges web publishers to explore geo - targeting andy hobsbawm wins the special lifetime achievement award at the inaugural imperatives space01 to shape clerical medical online emi music uk launches new content on the raft to celebrate 10 th anniversary online customer services market comes of age : uk revenues expected to double in 2005 according to e - consultancy space01 ensures bright grey gets brighter logan tod warns website owners about new google prefetch hidden costs b2 b websites overtake offline media as first for business information aop survey highlights online b2 b perfect for brand advertising aop predicts significant growth for b2 b sites aop research shows b2 b sites are snapping at the heels of search engines callgen first to bring cost - per - call ' to the uk specialmoves calls for full service agencies to outsource specialist interaction design natmag steps up to chair ppa interactive council cnet networks uk joins board of uk association of online publishers uk association of online publishers l <eos>\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl_evaluation.best_case(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<sos> aop urges web publishers to explore geo - targeting andy hobsbawm wins the special lifetime achievement award at the inaugural imperatives space01 to shape clerical medical online emi music uk launches new content on the raft to celebrate 10 th anniversary online customer services market comes of age : uk revenues expected to double in 2005 according to e - consultancy space01 ensures bright grey gets brighter logan tod warns website owners about new google prefetch hidden costs b2 b websites overtake offline media as first for business information aop survey highlights online b2 b perfect for brand advertising aop predicts significant growth for b2 b sites aop research shows b2 b sites are snapping at the heels of search engines callgen first to bring cost - per - call ' to the uk specialmoves calls for full service agencies to outsource specialist interaction design natmag steps up to chair ppa interactive council cnet networks uk joins board of uk association of online publishers uk association of online publishers l <eos>\",\n",
       " \"<sos> ( picture iii ) ; from p . mitchell , biological reviews 41 ( 1965 ) , cambridge university press ( picture iv ) ; from m . d . brand , ' the stoichiometric relationships between electron transport , proton translocation and adenosine triphosphate synthesis and hydrolysis in mitochondria ' , biochemical society transactions 5 ( 1977 ) , the biochemical society ( picture v ) ; from m . j . selwyn and a . p . dawson , ' model membranes and transport systems ' , biochemical society transactions 5 ( 1977 ) , the biochemical society ( picture vi ) ; from p . hinkle and r . mccarty , ' how cells make atp ' , scientific american , march 1978,238 , no.3 ( pictures vii and viii ) . vii preface the research reported in this book was conceived when a scientist friend showed us a copy of a letter written by a biochemist which seemed to indicate by its tone that there was a raging and , so we thought , sociologically interesting controversy going on in an area of biochemistry called ' oxidative phosphorylation ' . <eos> <pad>\",\n",
       " '<sos> the operation of a simple oscillator describe how to change the frequency of a clock circuit section 5 . analogue processes identify devices which contain amplifiers state the purpose of amplifiers in devices such as radios , music centres and intercoms describe how the input and output voltages might compare in an amplifier carry out calculations involving input voltage , output voltage and the voltage gain of an amplifier describe hot to measure the voltage gain of an amplifier state that the power may be calculated from p = v2 / r state that the power gain of an amplifier is the ratio of the power output to the power input i.e . gain = power out / power in carry out calculations involving the power gain of an amplifier space physics section 1 . signals from space state what is meant by the moon , a planet , the sun , a star , the solar system , a galaxy and the universe express the distances from the earth to the sun , to the next nearest star and to the edge of our galaxy in terms of the time it takes for <eos> <pad>']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl_evaluation.best_cases(\"accuracy\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> a woman dancing wildly . <eos>'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl_evaluation.worst_case(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> a woman dancing wildly . <eos>',\n",
       " '<sos> let us call you back <eos>',\n",
       " '<sos> though they happen . <eos> <pad>']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srl_evaluation.worst_cases(\"accuracy\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_evaluation.save(\"accuracy\")\n",
    "srl_evaluation.save(\"f1_macro\")\n",
    "srl_evaluation.save(\"f1_micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
